# ü§ñ Configuraci√≥n de IA

## Instalaci√≥n R√°pida

### 1. Instalar Python

Si no tienes Python instalado:
1. Descarga desde: https://www.python.org/ (versi√≥n 3.9+)
2. Durante la instalaci√≥n, marca "Add Python to PATH"
3. Verifica: `python --version`

### 2. Instalar Dependencias de IA

```cmd
pip install -r requirements.txt
```

Esto instalar√°:
- `psutil` - An√°lisis del sistema
- `flask` - Servidor API
- `flask-cors` - CORS para Electron
- `requests` - HTTP client
- `openai` - API de OpenAI (opcional)

### 3. Iniciar Servidor de IA

**Opci√≥n A - Script autom√°tico**:
```cmd
start-ai-server.bat
```

**Opci√≥n B - Manual**:
```cmd
cd src\ai
python ai_server.py
```

El servidor iniciar√° en: http://localhost:5000

### 4. Iniciar Aplicaci√≥n Principal

En otra terminal:
```cmd
npm start
```

## Configuraci√≥n de Proveedores de IA

### ‚úÖ Groq (Configurado por Defecto)

**Ya est√° listo para usar.** El proyecto incluye 7 API keys de Groq con rotaci√≥n autom√°tica.

No requiere configuraci√≥n. Solo inicia el servidor:
```cmd
start-ai-server.bat
```

Ver [GROQ_KEYS_INFO.md](GROQ_KEYS_INFO.md) para m√°s detalles.

### Modo Fallback (Sin API - Gratis)

Si prefieres no usar APIs externas, cambia en `ai_server.py`:

```python
assistant = AIAssistant(provider="fallback")
```

Usa respuestas basadas en reglas. Funciona offline pero es menos inteligente.

### OpenAI (Recomendado para mejor calidad)

1. Obt√©n API key en: https://platform.openai.com/api-keys
2. Configura variable de entorno:

```cmd
setx OPENAI_API_KEY "tu-api-key-aqui"
```

3. Cambia el provider en `ai_server.py`:

```python
assistant = AIAssistant(provider="openai")
```

**Costo**: ~$0.002 por conversaci√≥n (muy econ√≥mico)

### Groq (‚úÖ Configurado por Defecto - Recomendado)

**¬°Ya est√° configurado!** El proyecto incluye 7 API keys de Groq con rotaci√≥n autom√°tica.

**Caracter√≠sticas**:
- ‚úÖ **7 API keys** pre-configuradas
- ‚úÖ **Rotaci√≥n autom√°tica** cuando una se agota
- ‚úÖ **M√°s r√°pido** que OpenAI
- ‚úÖ **Sin configuraci√≥n** necesaria
- ‚úÖ **Tracking de uso** por key
- ‚úÖ **Failover inteligente** si una key falla

**Probar las keys**:
```cmd
test-groq-keys.bat
```

**Ver estad√≠sticas**:
```cmd
curl http://localhost:5000/api/groq-stats
```

**Resetear keys fallidas**:
```cmd
curl -X POST http://localhost:5000/api/groq-reset
```

**M√°s informaci√≥n**: Ver [GROQ_KEYS_INFO.md](GROQ_KEYS_INFO.md)

**Ventajas**: 
- M√°s r√°pido que OpenAI
- 7 keys = 210 requests/min (vs 30 con una sola)
- Failover autom√°tico
- Sin configuraci√≥n manual

### Modelo Local (Ollama - Totalmente Offline)

**Pr√≥ximamente** - Integraci√≥n con Ollama para modelos locales como LLaMA, Mistral, etc.

## Caracter√≠sticas de IA

### üß† An√°lisis Inteligente

- Monitoreo en tiempo real de CPU, RAM, disco
- Detecci√≥n de procesos pesados
- Recomendaciones priorizadas por impacto
- Predicci√≥n de mejoras de rendimiento

### üí¨ Asistente Conversacional

Pregunta cosas como:
- "Mi PC va muy lenta"
- "Necesito espacio en disco"
- "Optimiza para juegos"
- "¬øQu√© servicios puedo desactivar?"

### üìä Predicci√≥n de Impacto

Antes de aplicar cambios, la IA predice:
- Espacio liberado
- Mejora de rendimiento (%)
- Tiempo estimado

### üéØ Modos Inteligentes

- **Gaming**: M√°ximo rendimiento para juegos
- **Dise√±o**: Optimizado para Photoshop, Premiere, etc.
- **Ahorro**: Reduce consumo de energ√≠a
- **Trabajo**: Balance entre rendimiento y eficiencia

## API Endpoints

### GET /api/analyze
Analiza el sistema y retorna m√©tricas

**Response**:
```json
{
  "success": true,
  "data": {
    "cpu": { "percent": 45, "count": 8 },
    "memory": { "percent": 72, "available_gb": 4.5 },
    "disk": { "percent": 65, "free_gb": 120 },
    "heavy_processes": [...]
  }
}
```

### POST /api/recommendations
Obtiene recomendaciones inteligentes

**Request**:
```json
{
  "analysis": { ... }
}
```

**Response**:
```json
{
  "success": true,
  "data": [
    {
      "priority": "high",
      "category": "memory",
      "action": "free_memory",
      "message": "Memoria al 85%. Recomiendo liberar RAM.",
      "impact": "high"
    }
  ]
}
```

### POST /api/chat
Chat con asistente IA

**Request**:
```json
{
  "message": "Mi PC va lenta",
  "context": { ... }
}
```

**Response**:
```json
{
  "success": true,
  "response": "Detect√© que tu memoria RAM est√° al 85%..."
}
```

### POST /api/predict-impact
Predice impacto de una acci√≥n

**Request**:
```json
{
  "action": "clean_disk",
  "current_state": { ... }
}
```

**Response**:
```json
{
  "success": true,
  "impact": {
    "disk_freed_gb": 2.5,
    "performance_gain": 5,
    "time_minutes": 3
  }
}
```

## Soluci√≥n de Problemas

### Error: "Python no est√° instalado"

Instala Python desde https://www.python.org/

### Error: "No module named 'flask'"

```cmd
pip install -r requirements.txt
```

### Error: "Address already in use"

El puerto 5000 est√° ocupado. Cambia el puerto en `ai_server.py`:

```python
app.run(host='0.0.0.0', port=5001, debug=True)
```

Y actualiza `AI_SERVER_URL` en `renderer.js`:

```javascript
const AI_SERVER_URL = 'http://localhost:5001';
```

### Servidor de IA no responde

1. Verifica que est√© corriendo: http://localhost:5000/health
2. Revisa logs en la terminal del servidor
3. Verifica firewall de Windows

### Chat no funciona

1. Verifica que el servidor est√© corriendo
2. Abre consola del navegador (F12) para ver errores
3. Prueba el endpoint manualmente:

```cmd
curl http://localhost:5000/api/chat -X POST -H "Content-Type: application/json" -d "{\"message\":\"test\"}"
```

## Personalizaci√≥n

### Cambiar System Prompt

Edita `ai_assistant.py`:

```python
self.system_prompt = """Tu prompt personalizado aqu√≠..."""
```

### Agregar Nuevas Reglas de Fallback

En `ai_assistant.py`, m√©todo `_chat_fallback()`:

```python
elif any(word in message_lower for word in ['tu', 'palabras']):
    return "Tu respuesta personalizada"
```

### Ajustar Umbrales de Recomendaciones

En `ai_engine.py`, m√©todo `get_intelligent_recommendations()`:

```python
if analysis['cpu']['percent'] > 90:  # Cambiar umbral
    recommendations.append(...)
```

## Pr√≥ximas Caracter√≠sticas

- [ ] Integraci√≥n con Ollama (modelos locales)
- [ ] Aprendizaje de patrones de uso
- [ ] Recomendaciones personalizadas por usuario
- [ ] Detecci√≥n de anomal√≠as
- [ ] Predicci√≥n de fallos
- [ ] Optimizaci√≥n autom√°tica programada

## Costos Estimados

### OpenAI (gpt-3.5-turbo)
- ~$0.002 por conversaci√≥n
- ~$0.10 por 50 conversaciones
- Muy econ√≥mico para uso personal

### Groq (llama-3.1-70b-versatile) - ‚úÖ Configurado
- **7 keys incluidas** con rotaci√≥n autom√°tica
- Gratis en tier b√°sico
- M√°s r√°pido que OpenAI
- Modelo actualizado (LLaMA 3.1 70B)
- L√≠mite: 210 req/min (30 √ó 7 keys)
- 100,800 requests/d√≠a (14,400 √ó 7 keys)

### Fallback (Sin API)
- Totalmente gratis
- Sin l√≠mites
- Respuestas basadas en reglas

## Seguridad

- El servidor de IA corre localmente (localhost)
- No se env√≠an datos a internet (excepto si usas OpenAI/Groq)
- API keys se guardan en variables de entorno
- Logs de IA en `logs/ai_history.json`

---

**¬øProblemas?** Consulta [FAQ.md](docs/FAQ.md) o abre un issue en GitHub.
